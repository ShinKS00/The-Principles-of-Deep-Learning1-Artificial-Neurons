{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter.6.01 Polynomial Regression\n",
    "이번 PA 6.01에서는 Polynomial Regression을 진행하는데<br>\n",
    "실제 M차원에 따라서 어떻게 학습되는지 확인할 것입니다<br>\n",
    "모델은 다음과 같이 형성됩니다\n",
    "$$\\hat{y} =\\theta_{m}x^m +  \\theta_{m-1}x^{m-1} +...+ \\theta_{1}x^1 +  \\theta_{0}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import copy\n",
    "import basic_nodes as nodes\n",
    "import affine_MSE\n",
    "from tqdm import trange\n",
    "def get_data_batch(dataset, batch_idx, batch_size, n_batch):\n",
    "    if batch_idx is n_batch -1:\n",
    "        batch = dataset[batch_idx*batch_size:]\n",
    "    else:\n",
    "        batch = dataset[batch_idx*batch_size : (batch_idx+1)*batch_size]\n",
    "    return batch\n",
    "plt.style.use('seaborn')\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step.1 Dataset Generator\n",
    "200개의 Data Sample을 생성합니다<br>\n",
    "Input x_data는 [0.05 ~ 1 - 0.05]의 범위에서 생성합니다(np.linspace 사용)<br>\n",
    "y_data는 sin함수를 따라서 만들며 x_data를 통한 sin함수에 Noise를 추가합니다<br>\n",
    "h_oreder는 3차원으로 진행합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Start Dataset Preparation ###\n",
    "n_sample = \n",
    "h_order = \n",
    "\n",
    "x_data1 = \n",
    "y_data =\n",
    "### End Dataset Preparation ###\n",
    "x_data = np.zeros(shape = (n_sample, 1))\n",
    "for order in range(1, h_order + 1):\n",
    "    order_data = np.power(x_data1, order)\n",
    "    x_data = np.hstack((x_data, order_data))\n",
    "\n",
    "data = np.hstack((x_data, y_data))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step.2 Parameter 설정\n",
    "학습에 필요한 Parameter를 설정하고<br>\n",
    "5장 Multi-Variate-Linear-Regression에서 사용했던<br>\n",
    "Affine_Function과 MSE_Cost를 import하여 사용합니다<br>\n",
    "\n",
    "* batch_size = 32\n",
    "* epochs = 300000\n",
    "* lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_batch = np.ceil(data.shape[0]/batch_size).astype(int)\n",
    "feature_dim = x_data.shape[1]-1\n",
    "Th = np.ones(shape = (feature_dim + 1,), dtype = np.float).reshape(-1, 1)\n",
    "\n",
    "affine = affine_MSE.Affine_Function(feature_dim, Th)\n",
    "cost = affine_MSE.MSE_Cost()\n",
    "### Start Parameter Set ###\n",
    "epochs, lr = \n",
    "batch_size = \n",
    "### End Parameter Set ###\n",
    "th_accum = Th.reshape(-1, 1)\n",
    "cost_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step.3 Learning\n",
    "mini-batch를 통한 Data를 MVLR에서 Learning했던 것과 동일하게<br>\n",
    "Learning을 진행한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다만 $\\theta$가 데이터셋을 따라 자리 잡기까지<br>\n",
    "시간이 굉장히 오래 걸립니다<br>\n",
    "따라서 밤에 실행후 주무시고 일어나시면 될 것같습니다<br>\n",
    "보여드릴 코드는 h_order를 [3, 5, 7, 11] 4가지 Case를 통해서<br>\n",
    "동일한 Epoch동안 어떻게 학습되는지를 관찰 할 것인데<br>\n",
    "시간이 너무 오래 걸린다면 h_order 한가지만 해보셔도 됩니다<br>\n",
    "또한 Epoch를 300000이 아니라 줄이시고 해보셔도 됩니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in trange(epochs):\n",
    "    np.random.shuffle(data)\n",
    "    for batch_idx in range(n_batch):\n",
    "        ### Start Learning \n",
    "        batch = \n",
    "        X, Y =\n",
    "        Pred =\n",
    "        J = \n",
    "        \n",
    "        dPred = \n",
    "        affine.backward(dPred, lr)\n",
    "        \n",
    "        th_accum = np.hstack((th_accum, affine._Th))\n",
    "        cost_list.append(J)\n",
    "        ### End Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step.4 Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_data1,y_data,color = 'r')\n",
    "tmp_Th = copy.deepcopy(affine._Th)\n",
    "tmp_Th = tmp_Th.reshape((h_order+1))\n",
    "tmp_y_data = []\n",
    "for i in range(200):\n",
    "    tmp_y_data.append(np.sum(x_data[i] * tmp_Th))\n",
    "plt.plot(x_data1,tmp_y_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**\n",
    "<img src='./img/6_h3.png' width = 600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With h_order 5\n",
    "다른 조건들은 동일하게 진행하고 h_order를 5로 변경하여<br>\n",
    "학습을 진행합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Start Dataset Preparation ###\n",
    "n_sample = \n",
    "h_order = \n",
    "\n",
    "x_data1 = \n",
    "y_data =\n",
    "### End Dataset Preparation ###\n",
    "x_data = np.zeros(shape = (n_sample, 1))\n",
    "for order in range(1, h_order + 1):\n",
    "    order_data = np.power(x_data1, order)\n",
    "    x_data = np.hstack((x_data, order_data))\n",
    "\n",
    "data = np.hstack((x_data, y_data))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_batch = np.ceil(data.shape[0]/batch_size).astype(int)\n",
    "feature_dim = x_data.shape[1]-1\n",
    "Th = np.ones(shape = (feature_dim + 1,), dtype = np.float).reshape(-1, 1)\n",
    "\n",
    "affine = affine_MSE.Affine_Function(feature_dim, Th)\n",
    "cost = affine_MSE.MSE_Cost()\n",
    "### Start Parameter Set ###\n",
    "epochs, lr = \n",
    "batch_size = \n",
    "### End Parameter Set ###\n",
    "th_accum = Th.reshape(-1, 1)\n",
    "cost_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in trange(epochs):\n",
    "    np.random.shuffle(data)\n",
    "    for batch_idx in range(n_batch):\n",
    "        ### Start Learning \n",
    "        batch = \n",
    "        X, Y =\n",
    "        Pred =\n",
    "        J = \n",
    "        \n",
    "        dPred = \n",
    "        affine.backward(dPred, lr)\n",
    "        \n",
    "        th_accum = np.hstack((th_accum, affine._Th))\n",
    "        cost_list.append(J)\n",
    "        ### End Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_data1,y_data,color = 'r')\n",
    "tmp_Th = copy.deepcopy(affine._Th)\n",
    "tmp_Th = tmp_Th.reshape((h_order+1))\n",
    "tmp_y_data = []\n",
    "for i in range(200):\n",
    "    tmp_y_data.append(np.sum(x_data[i] * tmp_Th))\n",
    "plt.plot(x_data1,tmp_y_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**\n",
    "<img src='./img/6_h5.png' width = 600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With h_order 7\n",
    "다른 조건들은 동일하게 진행하고 h_order를 7로 변경하여<br>\n",
    "학습을 진행합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Start Dataset Preparation ###\n",
    "n_sample = \n",
    "h_order = \n",
    "\n",
    "x_data1 = \n",
    "y_data =\n",
    "### End Dataset Preparation ###\n",
    "x_data = np.zeros(shape = (n_sample, 1))\n",
    "for order in range(1, h_order + 1):\n",
    "    order_data = np.power(x_data1, order)\n",
    "    x_data = np.hstack((x_data, order_data))\n",
    "\n",
    "data = np.hstack((x_data, y_data))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_batch = np.ceil(data.shape[0]/batch_size).astype(int)\n",
    "feature_dim = x_data.shape[1]-1\n",
    "Th = np.ones(shape = (feature_dim + 1,), dtype = np.float).reshape(-1, 1)\n",
    "\n",
    "affine = affine_MSE.Affine_Function(feature_dim, Th)\n",
    "cost = affine_MSE.MSE_Cost()\n",
    "### Start Parameter Set ###\n",
    "epochs, lr = \n",
    "batch_size = \n",
    "### End Parameter Set ###\n",
    "th_accum = Th.reshape(-1, 1)\n",
    "cost_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in trange(epochs):\n",
    "    np.random.shuffle(data)\n",
    "    for batch_idx in range(n_batch):\n",
    "        ### Start Learning \n",
    "        batch = \n",
    "        X, Y =\n",
    "        Pred =\n",
    "        J = \n",
    "        \n",
    "        dPred = \n",
    "        affine.backward(dPred, lr)\n",
    "        \n",
    "        th_accum = np.hstack((th_accum, affine._Th))\n",
    "        cost_list.append(J)\n",
    "        ### End Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_data1,y_data,color = 'r')\n",
    "tmp_Th = copy.deepcopy(affine._Th)\n",
    "tmp_Th = tmp_Th.reshape((h_order+1))\n",
    "tmp_y_data = []\n",
    "for i in range(200):\n",
    "    tmp_y_data.append(np.sum(x_data[i] * tmp_Th))\n",
    "plt.plot(x_data1,tmp_y_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**\n",
    "<img src='./img/6_h7.png' width = 600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With h_order 11\n",
    "다른 조건들은 동일하게 진행하고 h_order를 11로 변경하여<br>\n",
    "학습을 진행합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Start Dataset Preparation ###\n",
    "n_sample = \n",
    "h_order = \n",
    "\n",
    "x_data1 = \n",
    "y_data =\n",
    "### End Dataset Preparation ###\n",
    "x_data = np.zeros(shape = (n_sample, 1))\n",
    "for order in range(1, h_order + 1):\n",
    "    order_data = np.power(x_data1, order)\n",
    "    x_data = np.hstack((x_data, order_data))\n",
    "\n",
    "data = np.hstack((x_data, y_data))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_batch = np.ceil(data.shape[0]/batch_size).astype(int)\n",
    "feature_dim = x_data.shape[1]-1\n",
    "Th = np.ones(shape = (feature_dim + 1,), dtype = np.float).reshape(-1, 1)\n",
    "\n",
    "affine = affine_MSE.Affine_Function(feature_dim, Th)\n",
    "cost = affine_MSE.MSE_Cost()\n",
    "### Start Parameter Set ###\n",
    "epochs, lr = \n",
    "batch_size = \n",
    "### End Parameter Set ###\n",
    "th_accum = Th.reshape(-1, 1)\n",
    "cost_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in trange(epochs):\n",
    "    np.random.shuffle(data)\n",
    "    for batch_idx in range(n_batch):\n",
    "        ### Start Learning \n",
    "        batch = \n",
    "        X, Y =\n",
    "        Pred =\n",
    "        J = \n",
    "        \n",
    "        dPred = \n",
    "        affine.backward(dPred, lr)\n",
    "        \n",
    "        th_accum = np.hstack((th_accum, affine._Th))\n",
    "        cost_list.append(J)\n",
    "        ### End Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_data1,y_data,color = 'r')\n",
    "tmp_Th = copy.deepcopy(affine._Th)\n",
    "tmp_Th = tmp_Th.reshape((h_order+1))\n",
    "tmp_y_data = []\n",
    "for i in range(200):\n",
    "    tmp_y_data.append(np.sum(x_data[i] * tmp_Th))\n",
    "plt.plot(x_data1,tmp_y_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**\n",
    "<img src='./img/6_h11.png' width = 600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Without Noise\n",
    "기존의 데이터셋에서 노이즈를 제거한 모습을 보게 되면<br>\n",
    "다음과 같다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 200\n",
    "\n",
    "x_data1 = np.linspace(0.05, 1 - 0.05, n_sample).reshape(-1, 1)\n",
    "y_data = np.sin(2*np.pi*x_data1) #+ 0.2*np.random.normal(0, 1, size = (n_sample,1))\n",
    "plt.scatter(x_data1,y_data,color = 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "결과를 비교해보면 h_order 가 3일때가 Dataset에 가장 맞는 학습 결과로 볼수 있다<br>\n",
    "강의에서 소개했던 Pattern Recognition and Machine learning을 보게되면<br>\n",
    "아래 사진과 같이 h_order가 높아질수록 overfitting의 위험성이 높아진다<br>\n",
    "하지만 h_order 11에서도 overfitting이 크게 발생하지 않았다<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./img/6_5.png' width = 600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그 이유는 다음의 그림과 같이 많은 데이터셋을 통해서<br>\n",
    "학습을 진행했기 때문에 Overfitting의 발생을 억제한 것이다<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./img/6_6.png' width = 600>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
